DAOBS orchestration
===================
This project orchestrates four containers, in order to serve the DAOBS dasboard application:
* [Dashboard](https://github.com/INSPIRE-MIF/daobs/): web app which collects information and configures indicators to generate reporting.
* [Elasticsearch](https://github.com/INSPIRE-MIF/daobs/tree/2.0.x/docker/elasticsearch): ElasticSearch image, with the readonlyrest plugin installed.
* [Kibana](https://github.com/elastic/kibana): Kibana 5 - official image from elastic.
* [Nginx](https://hub.docker.com/_/nginx/): web server; configured as a reverse proxy.
* [Cerebro](https://github.com/lmenezes/cerebro): tool to monitor the health of an elasticsearch cluster.

In order to optimize image size, whenever possible [alpine](https://alpinelinux.org/) based images are used as base images. The only image we build is the `dashboard`; all other images are pulled from the relevant repositories, and configured using configuration files on mounted volumes; the `kibana` image is pulled from the official elastic repositories, while `nginx` is pulled from the docker official repositories.

Both `elasticsearch` and `kibana` read their configurations from files generated by the top-level build. **Before running this composition, make sure to build this project** and pass it the relevant flags (by default using docker profile).

The containers are launched sequentially:
1. The first to start is `elasticsearch`.
2. The `kibana` container waits for ES, in order to start. It inserts the indexes, before launching the kibana app.
3. The `dashboard` container waits for kibana, in order to start. It backs up the indexes with ElasticDump, before launching the webserver.

The `nginx` container is not dependent from other containers and it is launched at the start.

The dashboard image
-------------------
The dashboard image is based on a maven-alpine linux image.
* It installs npm, tomcat and the ETF application.
* It builds the [daobs] project, using the src code on the top-level repository (`../`).
* It deploys the resulting war on Tomcat, using the application path as build argument.

The elasticsearch image
-----------------------
The elasticsearch image is based on the [official elasticsearch image](https://github.com/elastic/elasticsearch-docker/tree/5.5). It adds the [readonlyrest](https://readonlyrest.com/) plugin for supporting security & access control in Elasticsearch and Kibana.

INSTALL & RUN
=============
This is the configuration used to build and run the INSPIRE dashboards available at EEA. The process creates 2 images for the 2 types of dashboard app (sandbox and official), the build elasticsearch image with readonlyrest plugin and then run the composition.

```bash


# Download ETF
cd tasks/etf-validation-checker
mvn install -Drelax -DskipTests -Petf-download
cd ../..


# Build sandbox dashboard
mvn clean install -Peea-inspire-dashboard -Drelax -DskipTests

# Build official dashboard
mvn clean install -Peea-inspire-official -Drelax -DskipTests

# Build images: this will build & tag the sandbox-dashboard, official-dashboard, elasticsearch, kibana, nginx & cerebro images
cd docker
docker-compose -f docker-compose-build.yml build

# Start compositions
docker-compose -p dashboard-sandbox -f docker-compose-canonical.yml -f docker-compose-eea-dashboard-sandbox.yml up
docker-compose -p dashboard-official -f docker-compose-canonical.yml -f docker-compose-eea-dashboard-official.yml up

# publish images
docker push inspiremif/daobs-eea-dashboard-sandbox
docker push inspiremif/daobs-eea-dashboard-official
docker push inspiremif/elasticsearch
docker push inspiremif/kibana
docker push inspiremif/nginx
docker push inspiremif/cerebro

```
If you just want to build the images locally, you can use the [provided convenience script](https://github.com/INSPIRE-MIF/daobs/blob/2.0.x/docker/build_images.sh):

```bash
./build_images.sh
```

In alternative if you don't want to build anything, you may just use the images wich are hosted on docker hub. To run the `sandbox dashboard` orchestration:

```bash
docker-compose -p dashboard-sandbox -f docker-compose-canonical.yml -f docker-compose-eea-dashboard-sandbox.yml up -d
```

To run the `official dashboard` orchestration:

```bash
docker-compose -p dashboard-official -f docker-compose-canonical.yml -f docker-compose-eea-dashboard-official.yml up -d
```

Or just use the provided convenience scripts [run_dashboard_sandbox.sh](https://github.com/INSPIRE-MIF/daobs/blob/2.0.x/docker/run_dashboard_sandbox.sh) and [run_dashboard_official.sh](https://github.com/INSPIRE-MIF/daobs/blob/2.0.x/docker/run_dashboard_official.sh).

Then open the applications with:

* https://localhost:444
* https://localhost

The two orchestrations can be run, side-by-side in the same machine, as they have different namespaces for container, volumes and networks names.

Advanced Configuration
----------------------
Nginx is running on port 443|444 (it uses different ports in the official and sandbox applications, in order to enable both of them to bind to the localhost). It can be configured as a proxy, using `nginx/nginx.conf`. The current configuration forwards all root requests on port 80|81 to the dashboard containers:

```
location / {
    #dashboard application on the root
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header Host $http_host;
    proxy_set_header X-Forwarded-Proto https;
    proxy_redirect off;
    proxy_connect_timeout      240;
    proxy_send_timeout         240;
    proxy_read_timeout         240;
    # note, there is not SSL here! plain HTTP is used
    proxy_pass DASHBOARD_URL;
    proxy_redirect DASHBOARD_URL /;
```

Elasticsearch is configured with three nodes, and two `discovery.zen.minimum_master_nodes`, to avoid the [split brain effect]( https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain). As by the default configuration, these nodes can all act as master, data and ingest nodes. When the cluster starts, we set the `elasticsearch` node as master node.

You can check the status of the elastic search cluster with:
```bash
curl http://[ES_IP]:9200/_cluster/health?pretty
```

`ES_IP` should be replaced by the IP address of the elasticsearch container. You can get the IPv4 addresses of the containers in a docker network with:

```bash
docker network inspect [NETWORK] | jq .[].Containers
```

Where `[NETWORK]` should be replaced by the network name, for instance, "dashboardofficial_network-dashboard-official".

In alternative, check the cerebro monitoring page at:

```
http://[CEREBRO_IP]:9000
```

When setting an elasticsearch host on cerebro, *make sure use the container name (for instance "official-es0"), or to its IP address*:
```
http://[ES_IP]:9200
```

The readonlyrest plugin allows to implement security & access control for elasticsearch and kibana. In the elasticsearch image two users are created: one in the ["kibana_rw"] group and another in the ["kibana_srv"] group. The credentials for these users are set in the docker-compose file, in the section which corresponds to the master node of elasticsearch (called "elasticsearch"):

```
elasticsearch:
  [...]
  environment:
    [...]
    - KIBANA_SRV_PASSWORD=changeme
    - KIBANA_RW_USER=changeme
    - KIBANA_RW_PASSWORD=changeme
```

The `KIBANA_SRV_PASSWORD` variable sets the password for the `kibana_server` user. The `KIBANA_RW_USER` and `KIBANA_RW_PASSWORD` variables set the username and password of a user on the ["kibana_rw"] group.

Then you need to match the value of `KIBANA_SRV_PASSWORD` in the configuration of the dashboard:

```
dashboard:
    [...]
    environment:
    - KIBANA_SRV_PASSWORD=changeme # n.b.: must match the credentials on elasticsearch
```

And set the same value in the configuration of kibana:

```
kibana:
  [...]
  environment:
    - KIBANA_SRV_PASSWORD=changeme # n.b.: must match the credentials on elasticsearch
```

Persisted Volumes
-----------------
The folder `/usr/share/elasticsearch/data` is persisted to a named volume, whose name depends on the node and orchestration. Unless explicitly removed, this volume will be persisted on the host folder: `var/lib/docker/volumes/[NAMED_VOLUME]/_data`, where [NAMED_VOLUME] should be replaced by the actual volume name.
The folder `/daobs-data-dir/`, which is mapped in the dockerfile to environmental variable `INSTALL_DASHBOARD_PATH`, is persisted in a volume whose name depends on the orchestration (e.g.: "dashboardsandbox_dashboard-sandbox-dir", "dashboardofficial_dashboard-official-dir")`. If you change `INSTALL_DASHBOARD_PATH` on the dockerfile, remember to also change the mapping on docker-compose, or your data directory won't be persisted.

Security
--------
Only the web container (nginx) publishes its ports (either 80 or 443). All other containers communicate *only* using docker's internal network.

On this orchestration, **SSL is enabled** by default.
In order to setup SSL with your own certificates, on the nginx section of docker-compose-canonical.yml you need to set the environmental variable `GENERATESSL` to `NO`.
Please check also the bind mounts, on the volume section, and make sure that they point to the location of your public certificate and private key; by default they point to `/etc/pki/tls/certs/server-eionet.crt` and `/etc/pki/tls/private/server-eionet.key`.

```
volumes:
  - /etc/localtime:/etc/localtime:ro
  - /etc/pki/tls/certs/server-eionet.crt:/tmp/cert.crt:ro
  - /etc/pki/tls/private/server-eionet.key:/tmp/priv.key:ro
```
If you don't have any keys, make sure to set set the environmental variable `GENERATESSL` to `YES`: a runtime script will generate **self-signed certificates**, which will enable you to use SSL on a development environment. You can set the certificate subject of the generated certificates, wih an additional environmental variable: `CERTIFICATESUBJ`. Self-signed certificates will issue an warning in the browser and need to be trusted by the user. It is not recommended to use self-signed certificates in production environments.

![Generated self-signed certificate](https://raw.githubusercontent.com/INSPIRE-MIF/daobs/2.0.x/docker/ssl.png)

License
========
View [license information](https://github.com/INSPIRE-MIF/daobs/blob/2.0.x/LICENCE.md) for the software contained in this image.
